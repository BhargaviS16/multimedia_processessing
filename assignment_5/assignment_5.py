# -*- coding: utf-8 -*-
"""assignment_5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucOw4tQI8CUpGen7a8oqhQXF2HdfWw-s
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from tabulate import tabulate

def load_and_preprocess_data():
    url = "https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data"
    feature_names = [
        'class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',
        'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',
        'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',
        'stalk-surface-below-ring', 'stalk-color-above-ring',
        'stalk-color-below-ring', 'veil-type', 'veil-color',
        'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'
    ]

    data = pd.read_csv(url, header=None, names=feature_names)
    data = data.replace('?', pd.NA).dropna()

    encoders = {col: LabelEncoder().fit(data[col]) for col in data.columns}
    data = data.apply(lambda x: encoders[x.name].transform(x))

    return data.drop('class', axis=1), data['class'], encoders

def reduce_dimensions(X, n_components=2):
    pca = PCA(n_components=n_components)
    X_reduced = pca.fit_transform(X)
    return StandardScaler().fit_transform(X_reduced)

def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    train_acc = accuracy_score(y_train, model.predict(X_train))
    test_acc = accuracy_score(y_test, model.predict(X_test))

    print(f"\n{model_name} Performance:")
    print(f"Training Accuracy: {train_acc * 100:.2f}%")
    print(f"Test Accuracy: {test_acc * 100:.2f}%")
    print(f"Training Time: {training_time:.4f} seconds")

    return model, train_acc, test_acc, training_time

def plot_decision_boundary(X, y, classifier, title):
    cmap = ListedColormap(['red', 'green'])
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                         np.arange(y_min, y_max, 0.01))

    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(8, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap)
    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k', cmap=cmap)
    plt.title(title)
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.show()

def main():
    X, y, _ = load_and_preprocess_data()
    X_reduced = reduce_dimensions(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_reduced, y, test_size=0.2, random_state=42
    )

    models = {
        "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
        "AdaBoost": AdaBoostClassifier(n_estimators=50, random_state=42)
    }

    results = []
    for name, model in models.items():
        trained_model, train_acc, test_acc, time_taken = evaluate_model(
            model, X_train, y_train, X_test, y_test, name
        )
        results.append({
            'Model': name,
            'Training Accuracy': train_acc,
            'Test Accuracy': test_acc,
            'Training Time (s)': time_taken
        })

        plot_decision_boundary(X_test, y_test, trained_model, f"Decision Boundary - {name}")

    results_df = pd.DataFrame(results)
    print("\nModel Comparison Summary:")
    print(tabulate(
        results_df.sort_values('Test Accuracy', ascending=False),
        headers='keys',
        tablefmt='pretty',
        floatfmt=".4f",
        showindex=False
    ))

    # Visual comparison
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.bar(results_df['Model'], results_df['Test Accuracy'], color='skyblue')
    plt.title('Test Accuracy Comparison')
    plt.ylim(0.95, 1.0)
    plt.xticks(rotation=45)

    plt.subplot(1, 2, 2)
    plt.bar(results_df['Model'], results_df['Training Time (s)'], color='salmon')
    plt.title('Training Time (seconds)')
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.show()

    # Best model
    best_model = results_df.loc[results_df['Test Accuracy'].idxmax()]
    print(f"""**Best Model Recommendation**
   - Model: {best_model['Model']}
   - Test Accuracy: {best_model['Test Accuracy']*100:.2f}%
   - Training Accuracy: {best_model['Training Accuracy']*100:.2f}%
   - Training Time: {best_model['Training Time (s)']:.4f}s""")



if __name__ == "__main__":
    main()