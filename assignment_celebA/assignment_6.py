# -*- coding: utf-8 -*-
"""assignment_6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RB9TfrsOHHSzOxkz-jeqoCQZBAKsDGIK
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("jessicali9530/celeba-dataset")

print("Path to dataset files:", path)

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Subset
from torchvision import transforms, datasets
import matplotlib.pyplot as plt
import numpy as np

class MustacheDetector:
    def __init__(self):
        # Initialize device and random seed
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        torch.manual_seed(42)

        # Configuration parameters
        self.batch_size = 30
        self.num_epochs = 15
        self.mustache_attr_idx = 12  # Mustache attribute index in CelebA

        # Initialize model and training components
        self.model = self._create_model().to(self.device)
        self.criterion = nn.BCELoss()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)

    def _create_model(self):
        """Build a convolutional neural network for binary classification"""
        return nn.Sequential(
            # Feature extraction blocks
            nn.Conv2d(3, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout(0.3),

            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout(0.3),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),

            # Classification head
            nn.Flatten(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def _get_transforms(self):
        """Define image transformations for training and validation"""
        train_transform = transforms.Compose([
            transforms.RandomHorizontalFlip(),
            transforms.CenterCrop(148),
            transforms.Resize(64),
            transforms.ToTensor(),
        ])

        val_transform = transforms.Compose([
            transforms.CenterCrop(148),
            transforms.Resize(64),
            transforms.ToTensor(),
        ])

        return train_transform, val_transform

    def prepare_datasets(self):
        """Load and prepare CelebA datasets for mustache detection"""
        train_transform, val_transform = self._get_transforms()

        # Convert -1/1 labels to 0/1 for binary classification
        target_transform = lambda attr: (attr[self.mustache_attr_idx] + 1) // 2

        # Load datasets
        train_set = datasets.CelebA(
            root='.',
            split='train',
            target_type='attr',
            transform=train_transform,
            target_transform=target_transform,
            download=True # Change download to True to download the dataset
)

        val_set = datasets.CelebA(
            root='.',
            split='valid',
            target_type='attr',
            transform=val_transform,
            target_transform=target_transform,
            download=True # Change download to True to download the dataset
)

        test_set = datasets.CelebA(
            root='.',
            split='test',
            target_type='attr',
            transform=val_transform,
            target_transform=target_transform,
            download=True # Change download to True to download the dataset
)
        # Create smaller subsets for faster training
        train_set = Subset(train_set, indices=torch.arange(12000))
        val_set = Subset(val_set, indices=torch.arange(1500))

        return train_set, val_set, test_set

    def train_model(self, train_loader, val_loader):
        """Train the model with early stopping"""
        best_val_acc = 0
        patience = 3
        patience_counter = 0

        train_history = {'loss': [], 'accuracy': []}
        val_history = {'loss': [], 'accuracy': []}

        for epoch in range(self.num_epochs):
            # Training phase
            self.model.train()
            epoch_loss = 0
            correct = 0
            total = 0

            for images, labels in train_loader:
                images, labels = images.to(self.device), labels.to(self.device)

                self.optimizer.zero_grad()
                outputs = self.model(images).squeeze()
                loss = self.criterion(outputs, labels.float())
                loss.backward()
                self.optimizer.step()

                epoch_loss += loss.item() * labels.size(0)
                predicted = (outputs >= 0.5).float()
                correct += (predicted == labels).sum().item()
                total += labels.size(0)

            train_history['loss'].append(epoch_loss / total)
            train_history['accuracy'].append(correct / total)

            # Validation phase
            val_loss, val_acc = self.evaluate(val_loader)
            val_history['loss'].append(val_loss)
            val_history['accuracy'].append(val_acc)

            print(f"Epoch {epoch+1}/{self.num_epochs}: "
                  f"Train Loss: {train_history['loss'][-1]:.4f}, "
                  f"Train Acc: {train_history['accuracy'][-1]:.4f} | "
                  f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

            # Early stopping check
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_model.pth')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print("Early stopping triggered")
                    break

        # Load best model weights
        self.model.load_state_dict(torch.load('best_model.pth'))
        return train_history, val_history

    def evaluate(self, loader):
        """Evaluate model performance on given data loader"""
        self.model.eval()
        loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in loader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = self.model(images).squeeze()
                loss += self.criterion(outputs, labels.float()).item() * labels.size(0)
                predicted = (outputs >= 0.5).float()
                correct += (predicted == labels).sum().item()
                total += labels.size(0)

        return loss / total, correct / total

    def visualize_results(self, history, loader, num_samples=8):
        """Visualize training progress and sample predictions"""
        # Plot training curves
        plt.figure(figsize=(12, 5))

        plt.subplot(1, 2, 1)
        plt.plot(history[0]['loss'], label='Train Loss')
        plt.plot(history[1]['loss'], label='Val Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        plt.subplot(1, 2, 2)
        plt.plot(history[0]['accuracy'], label='Train Accuracy')
        plt.plot(history[1]['accuracy'], label='Val Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()

        plt.tight_layout()
        plt.show()

        # Visualize sample predictions
        self.model.eval()
        images, labels = next(iter(loader))
        images, labels = images.to(self.device), labels.to(self.device)

        with torch.no_grad():
            outputs = self.model(images).squeeze()
            probs = outputs.cpu().numpy()
            preds = (outputs >= 0.5).float().cpu().numpy()

        plt.figure(figsize=(15, 5))
        for i in range(num_samples):
            plt.subplot(1, num_samples, i+1)
            plt.imshow(images[i].cpu().permute(1, 2, 0))
            plt.title(f"Label: {'Yes' if labels[i] == 1 else 'No'}\n"
                     f"Pred: {'Yes' if preds[i] == 1 else 'No'} ({probs[i]:.2f})")
            plt.axis('off')
        plt.tight_layout()
        plt.show()

# Main execution
if __name__ == "__main__":
    print("Initializing mustache detection system...")
    detector = MustacheDetector()

    print("Preparing datasets...")
    train_set, val_set, test_set = detector.prepare_datasets()

    print("Creating data loaders...")
    train_loader = DataLoader(train_set, batch_size=detector.batch_size, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=detector.batch_size, shuffle=False)
    test_loader = DataLoader(test_set, batch_size=detector.batch_size, shuffle=False)

    print("\nTraining model...")
    train_hist, val_hist = detector.train_model(train_loader, val_loader)

    print("\nEvaluating on test set...")
    test_loss, test_acc = detector.evaluate(test_loader)
    print(f"Test Accuracy: {test_acc:.4f}")

    print("\nVisualizing results...")
    detector.visualize_results((train_hist, val_hist), test_loader)