# -*- coding: utf-8 -*-
"""ch.04

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KD2d1pQeQ7rNlQFKhUQzt2EJyMJ-sACy
"""

# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
from mlxtend.feature_selection import SequentialFeatureSelector as SFS

# ====== Step 1: Load and Prepare Data ======
def load_and_prepare_data(file_path):
    """Load the dataset, preprocess it, and split into training and testing sets."""
    # Load the dataset
    dataset = pd.read_csv(file_path, header=None)

    # Assign meaningful column names
    dataset.columns = [
        'Area', 'Perimeter', 'Compactness', 'Kernel_Length', 'Kernel_Width',
        'Asymmetry_Coefficient', 'Kernel_Groove_Length', 'Class_Label'
    ]

    # Separate features (X) and target (y)
    features = dataset.iloc[:, :-1].values
    target = dataset.iloc[:, -1].values

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        features, target, test_size=0.3, random_state=42, stratify=target
    )

    # Normalize the features using StandardScaler
    scaler = StandardScaler()
    X_train_normalized = scaler.fit_transform(X_train)
    X_test_normalized = scaler.transform(X_test)

    return X_train_normalized, X_test_normalized, y_train, y_test, dataset

# ====== Step 2: Train and Evaluate Models ======
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    """Train and print model accuracy & classification reports."""
    models = {
        "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
        "K-Nearest Neighbors (KNN)": KNeighborsClassifier(n_neighbors=5),
        "Support Vector Machine (SVM)": SVC(kernel='linear', C=1.0),
        "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),
    }

    print("\nClasses found in dataset:", np.unique(y_train))

    for model_name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred)

        # Print accuracy and classification report
        print(f"\nModel: {model_name}")
        print(f"Accuracy: {accuracy:.4f}")
        print(report)

    return models

# ====== Step 3: Visualize Feature Importance ======
def visualize_feature_importance(models, dataset):
    """Plot feature importance for Decision Tree and Random Forest models."""
    for name, model in models.items():
        if hasattr(model, "feature_importances_"):
            plt.figure(figsize=(8, 5))
            plt.bar(dataset.columns[:-1], model.feature_importances_, color='skyblue')
            plt.xticks(rotation=45)
            plt.ylabel("Importance Score")
            plt.title(f"Feature Importance - {name}")
            plt.grid(axis='y', linestyle='--')
            plt.show()

# ====== Step 4: Evaluate KNN Performance ======
def evaluate_knn_performance(X_train, X_test, y_train, y_test):
    """Plot the accuracy of KNN for different numbers of neighbors."""
    neighbor_range = np.arange(1, 20)
    train_scores, test_scores = [], []

    for k in neighbor_range:
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(X_train, y_train)
        train_scores.append(knn.score(X_train, y_train))
        test_scores.append(knn.score(X_test, y_test))

    # Plot the results
    plt.figure(figsize=(8, 5))
    plt.plot(neighbor_range, train_scores, label="Training Accuracy", marker='o', color='navy')
    plt.plot(neighbor_range, test_scores, label="Testing Accuracy", marker='s', color='orange')
    plt.xlabel("Number of Neighbors (k)")
    plt.ylabel("Accuracy")
    plt.title("KNN: Training vs Testing Accuracy")
    plt.legend()
    plt.grid(True)
    plt.show()

# ====== Step 5: Analyze Feature Selection Impact ======
def analyze_feature_selection(X_train, y_train):
    """Evaluate the impact of feature selection on model accuracy using SFS."""
    knn = KNeighborsClassifier(n_neighbors=5)
    sfs = SFS(knn, k_features='best', forward=False, scoring='accuracy', cv=5)
    sfs.fit(X_train, y_train)

    # Extract and plot accuracy scores
    feature_counts = list(sfs.subsets_.keys())
    accuracies = [sfs.subsets_[k]['avg_score'] for k in feature_counts]

    plt.figure(figsize=(8, 5))
    plt.plot(feature_counts, accuracies, marker='o', linestyle='-', color='purple')
    plt.xlabel("Number of Features")
    plt.ylabel("Cross-Validation Accuracy")
    plt.title("Feature Selection Impact on Model Accuracy")
    plt.grid(True)
    plt.show()

# ====== Step 6: Explore SVM Regularization ======
def explore_svm_regularization(X_train, y_train):
    """Visualize the effect of regularization strength (C) on SVM weights."""
    C_values = np.logspace(-4, 4, 10)
    weights = []

    for c in C_values:
        svm = SVC(kernel='linear', C=c)
        svm.fit(X_train, y_train)
        weights.append(svm.coef_[0])

    weights = np.array(weights)

    # Plot the regularization path
    plt.figure(figsize=(8, 5))
    colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']
    for i, color in enumerate(colors[:weights.shape[1]]):
        plt.plot(C_values, weights[:, i], label=f"Feature {i+1}", color=color)

    plt.axhline(0, color='gray', linestyle='--', linewidth=2)
    plt.xscale('log')
    plt.xlabel("Regularization Strength (C)")
    plt.ylabel("Weight Magnitude")
    plt.title("SVM Regularization Path")
    plt.legend(loc='upper right')
    plt.grid(True)
    plt.show()

# ====== Main Execution ======
if __name__ == "__main__":
    # Load and preprocess the data
    data_file = "/content/wheat_seeds_clean.csv"
    X_train, X_test, y_train, y_test, dataset = load_and_prepare_data(data_file)

    # Train models and print results
    models = train_and_evaluate_models(X_train, X_test, y_train, y_test)

    # Visualize feature importance
    visualize_feature_importance(models, dataset)

    # Evaluate KNN performance
    evaluate_knn_performance(X_train, X_test, y_train, y_test)

    # Analyze feature selection impact
    analyze_feature_selection(X_train, y_train)

    # Explore SVM regularization
    explore_svm_regularization(X_train, y_train)